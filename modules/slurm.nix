{ config, lib, options, pkgs, ... }:

with lib;

let
  settingsFormat = let
    listSep = ",";
    allowedTypes = with types; [ bool int float str attrs ];

    entryToString = key: val:
        if isAttrs val then concatStringsSep "\n" (mapAttrsToList (subKey: subVal: "${key}=${subKey} ${valueToString subVal}") val)
        else "${key}=${valueToString val}";

    valueToString = val:
        if isList val then concatStringsSep listSep (map (x: valueToString x) val)
        else if isBool val then (if val then "YES" else "NO")
        else if isAttrs val then concatStringsSep " " (mapAttrsToList (k: v: "${k}=${valueToString v}") val)
        else toString val;

    in {
      type = with types; let
        valueType = oneOf ([
          (listOf valueType)
        ] ++ allowedTypes) // {
          description = "Format of slurm config files.";
        };
      in attrsOf valueType;

      generate = name: value:
        pkgs.writeTextDir name (( concatStringsSep "\n" (
          mapAttrsToList (key: val: entryToString key val ) value )) + "\n");
   };

  cfg = config.services.slurm;
  opt = options.services.slurm;
  # configuration file can be generated by http://slurm.schedmd.com/configurator.html

  defaultUser = "slurm";

  configFile = settingsFormat.generate "slurm.conf" cfg.settings;

  plugStackConfig = pkgs.writeTextDir "plugstack.conf"
    ''
      ${optionalString cfg.enableSrunX11 "optional ${pkgs.slurm-spank-x11}/lib/x11.so"}
      ${cfg.extraPlugstackConfig}
    '';

  cgroupConf = settingsFormat.generate "cgroup.conf" cfg.settingsCgroup;

  slurmdbdConf = settingsFormat.generate "slurmdbd.conf" cfg.dbdserver.settings;

  # slurm expects some additional config files to be
  # in the same directory as slurm.conf
  etcSlurm = pkgs.symlinkJoin {
    name = "etc-slurm";
    paths = [ configFile cgroupConf plugStackConfig ] ++ cfg.extraConfigPaths;
  };

  SLURM_CONF = "${etcSlurm}/slurm.conf";

in {
  ###### interface

  meta.maintainers = [ maintainers.markuskowa ];

  options = {

    services.slurm = {

      server = {
        enable = mkOption {
          type = types.bool;
          default = false;
          description = ''
            Whether to enable the slurm control daemon.
            Note that the standard authentication method is "munge".
            The "munge" service needs to be provided with a password file in order for
            slurm to work properly (see <literal>services.munge.password</literal>).
          '';
        };
      };

      settings = mkOption {
        type = types.submodule {
          freeformType = settingsFormat.type;
          options = {};
        };

        description = ''
          Contents of <literal>slurm.conf</literal>.
          An interactive configuration generator can be found <link xlink:href="http://slurm.schedmd.com/configurator.html">here</link>.
        '';

        example = literalExpression ''
          settings = {
            SlurmctldHost = "control";
            nodeName = {
              "node[1-2]" = {
                CPUs = 4;
                State = "UNKNOWN";
              };
              "node[3-4]" = {
                CPUs = 48;
                State = "UNKNOWN";
              };
            };
            partitionName = {
              debug = {
                Nodes = "node[1-2]";
                Default = true;
                MaxTime = "INFINITE";
                State = "UP";
              };
              big = {
                Nodes = "node[3-4]";
                State = "UP";
              };
            };
          };
        '';
      };

      dbdserver = {
        enable = mkEnableOption "SlurmDBD service";

        storagePassFile = mkOption {
          type = with types; nullOr str;
          default = null;
          description = ''
            Path to file with database password. The content of this will be used to
            create the password for the <literal>StoragePass</literal> option.
          '';
        };

        settings = mkOption {
          type = types.submodule {
            freeformType = settingsFormat.type;

            options = {};
          };
          description = "Contents of <literal>slurmdbd.conf</literal>.";
        };
      };

      client = {
        enable = mkEnableOption "slurm client daemon";
      };

      enableStools = mkOption {
        type = types.bool;
        default = false;
        description = ''
          Whether to provide a slurm.conf file.
          Enable this option if you do not run a slurm daemon on this host
          (i.e. <literal>server.enable</literal> and <literal>client.enable</literal> are <literal>false</literal>)
          but you still want to run slurm commands from this host.
        '';
      };

      package = mkOption {
        type = types.package;
        default = pkgs.slurm.override { enableX11 = ! cfg.enableSrunX11; };
        defaultText = literalExpression "pkgs.slurm";
        example = literalExpression "pkgs.slurm";
        description = "The package to use for slurm binaries.";
      };

      enableSrunX11 = mkOption {
        default = false;
        type = types.bool;
        description = ''
          If enabled srun will accept the option "--x11" to allow for X11 forwarding
          from within an interactive session or a batch job. This activates the
          slurm-spank-x11 module. Note that this option also enables
          <option>services.openssh.forwardX11</option> on the client.

          This option requires slurm to be compiled without native X11 support.
          The default behavior is to re-compile the slurm package with native X11
          support disabled if this option is set to true.

          To use the native X11 support add <literal>PrologFlags=X11</literal> in <option>extraConfig</option>.
          Note that this method will only work RSA SSH host keys.
        '';
      };

      user = mkOption {
        type = types.str;
        default = defaultUser;
        description = ''
          Set this option when you want to run the slurmctld daemon
          as something else than the default slurm user "slurm".
          Note that the UID of this user needs to be the same
          on all nodes.
        '';
      };

      extraPlugstackConfig = mkOption {
        default = "";
        type = types.lines;
        description = ''
          Extra configuration that will be added to the end of <literal>plugstack.conf</literal>.
        '';
      };

      settingsCgroup = mkOption {
        type = types.submodule {
          freeformType = settingsFormat.type;

          options = {};
        };
        default = {};
        description = "Contents of <literal>cgroup.conf</literal>.";
      };

      extraConfigPaths = mkOption {
        type = with types; listOf path;
        default = [];
        description = ''
          Slurm expects config files for plugins in the same path
          as <literal>slurm.conf</literal>. Add extra nix store
          paths that should be merged into same directory as
          <literal>slurm.conf</literal>.
        '';
      };

      etcSlurm = mkOption {
        type = types.path;
        internal = true;
        readOnly = true;
        default = etcSlurm;
        defaultText = literalDocBook ''
          Directory created from generated config files and
          <literal>config.${opt.extraConfigPaths}</literal>.
        '';
        description = ''
          Path to directory with slurm config files. This option is set by default from the
          Slurm module and is meant to make the Slurm config file available to other modules.
        '';
      };

    };

  };

  ###### implementation

  config =
    mkIf ( cfg.enableStools ||
           cfg.client.enable ||
           cfg.server.enable ||
           cfg.dbdserver.enable ) {

    assertions = [ {
      assertion = ( cfg.enableStools || cfg.client.enable || cfg.server.enable ) ->
        ( cfg.settings ? ControlMachine || cfg.settings ? SlurmctldHost);
      message = ''
        Neither services.slurm.settings.ControlMachine nor services.slurm.settings.SlurmctldHost is set,
        but Slurm services are requested in the configuation.
        Please set services.slurm.settings.SlurmctldHost to the hostname running slurmcltd.
      '';
    }];

    environment = {
      systemPackages = [ cfg.package ];
      variables = { inherit SLURM_CONF; };
    };

    services.slurm.settings = {
      ClusterName = mkDefault "default";
      StateSaveLocation = mkDefault "/var/spool/slurmctld";
      SlurmdSpoolDir = mkDefault "/var/spool/slurmd";
      PlugStackConfig = mkDefault "${plugStackConfig}/plugstack.conf";
      SlurmUser = mkDefault cfg.user;
      ProctrackType = mkDefault "proctrack/linuxproc";
    };

    services.munge.enable = mkDefault true;

    # use a static uid as default to ensure it is the same on all nodes
    users.users.slurm = mkIf (cfg.user == defaultUser) {
      name = defaultUser;
      group = "slurm";
      uid = config.ids.uids.slurm;
    };

    users.groups.slurm.gid = config.ids.uids.slurm;

    systemd.services.slurmd = mkIf cfg.client.enable {
      path = with pkgs; [ cfg.package coreutils ]
        ++ lib.optional cfg.enableSrunX11 slurm-spank-x11;

      environment = { inherit SLURM_CONF; };

      wantedBy = [ "multi-user.target" ];
      after = [ "systemd-tmpfiles-clean.service" ];
      requires = [ "network.target" ];

      serviceConfig = {
        Type = "forking";
        KillMode = "process";
        ExecStart = "${cfg.package}/bin/slurmd";
        PIDFile = "/run/slurmd.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
        LimitMEMLOCK = "infinity";
      };
    };

    systemd.tmpfiles.rules = optional cfg.client.enable
      "d ${cfg.settings.SlurmdSpoolDir} 755 root root -"
       ++ optional cfg.server.enable
      "d ${cfg.settings.StateSaveLocation} 700 ${cfg.user} root -";

    services.openssh.forwardX11 = mkIf cfg.client.enable (mkDefault true);

    systemd.services.slurmctld = mkIf cfg.server.enable {
      path = with pkgs; [ cfg.package munge coreutils ]
        ++ lib.optional cfg.enableSrunX11 slurm-spank-x11;

      environment = { inherit SLURM_CONF; };

      wantedBy = [ "multi-user.target" ];
      after = [ "network.target" "munged.service" ];
      requires = [ "munged.service" ];

      serviceConfig = {
        Type = "forking";
        ExecStart = "${cfg.package}/bin/slurmctld";
        PIDFile = "/run/slurmctld.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
      };
    };

    services.slurm.dbdserver.settings = {
      DbdHost = mkDefault config.networking.hostName;
      SlurmUser = mkDefault cfg.user;
      StorageType = mkDefault "accounting_storage/mysql";
      StorageUser = mkDefault "slurm";
    };

    systemd.services.slurmdbd = let
      # slurm strips the last component off the path
      configPath = "$RUNTIME_DIRECTORY/slurmdbd.conf";
    in mkIf cfg.dbdserver.enable {
      path = with pkgs; [ munge coreutils ];

      wantedBy = [ "multi-user.target" ];
      after = [ "network.target" "munged.service" "mysql.service" ];
      requires = [ "munged.service" "mysql.service" ];

      preStart = ''
        install -m 600 -o ${cfg.dbdserver.settings.SlurmUser} \
          -T ${slurmdbdConf}/slurmdbd.conf ${configPath}

        ${optionalString (cfg.dbdserver.storagePassFile != null) ''
          echo "StoragePass=$(cat ${cfg.dbdserver.storagePassFile})" \
            >> ${configPath}
        ''}
      '';

      script = ''
        export SLURM_CONF=${configPath}
        exec ${cfg.package}/bin/slurmdbd -D
      '';

      serviceConfig = {
        RuntimeDirectory = "slurmdbd";
        Type = "simple";
        PIDFile = "/run/slurmdbd.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
      };
    };
  };
}
